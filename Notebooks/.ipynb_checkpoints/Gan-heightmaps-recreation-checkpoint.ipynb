{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78409352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings # We'll use this to suppress warnings caused by TensorFlow\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "print(np.__version__)\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # generating plot\n",
    "\n",
    "import tensorflow as tf # modeling/training\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "import time # Used for epoch timing\n",
    "\n",
    "import imageio # GIF generation\n",
    "import glob # GIF generation\n",
    "import PIL # GIF generation\n",
    "\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"textures_v2_brown500_with_valid.h5\"\n",
    "f = h5py.File(dataset_dir, 'r')\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b46b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_yt = np.concatenate((f['yt'][:]/255.0, f['xt'][:]/255.0), axis=3)\n",
    "full_dataset_yv = np.concatenate(((f['yv'][:] - 127.5) / 127.5, (f['xv'][:] - 127.5) / 127.5), axis=3)\n",
    "full_dataset = np.concatenate((full_dataset_yt, full_dataset_yv))\n",
    "full_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56fb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generator\n",
    "imgen = ImageDataGenerator(horizontal_flip = True, vertical_flip=True, rotation_range=360, fill_mode=\"reflect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "img_it = imgen.flow(tf.cast(full_dataset, dtype=tf.float32), None, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f1304",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = img_it.next()\n",
    "for x in range(len(examples)):\n",
    "    plt.subplot(4,4,x*2+1)\n",
    "    plt.imshow((examples[x][:,:,0:3]*127.5+127.5)/255.0)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(4,4,x*2+2)\n",
    "    plt.imshow(examples[x][:,:,3], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "def make_hm_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(4*4*512, input_shape=(1000,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Reshape((4, 4, 512)))\n",
    "    \n",
    "    assert model.output_shape == (None, 4, 4, 512)\n",
    "\n",
    "    div = [2,2,4,4,8,8,8]\n",
    "    div = [512/elem for elem in div]\n",
    "\n",
    "    for n in div:\n",
    "        model.add(layers.Conv2D(n, 5, strides=1, padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU(0.2))\n",
    "        model.add(layers.UpSampling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(1, 5, strides=1, padding='same', activation='sigmoid'))\n",
    "    assert model.output_shape == (None, 512, 512, 1)\n",
    "\n",
    "    return model\n",
    "\n",
    "def make_p2p_generator_model():\n",
    "    i = layers.Input(shape=[512, 512, 1])\n",
    "    \n",
    "    conv1 = layers.Conv2D(64, 3, strides=2, padding='same')(i)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    x = layers.LeakyReLU(0.01)(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(64*2, 3, strides=2, padding='same')(x)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    x = layers.LeakyReLU(0.01)(conv2)\n",
    "    \n",
    "    conv3 = layers.Conv2D(64*4, 3, strides=2, padding='same')(x)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    x = layers.LeakyReLU(0.01)(conv3)\n",
    "    \n",
    "    conv4 = layers.Conv2D(64*8, 3, strides=2, padding='same')(x)\n",
    "    conv4 = layers.BatchNormalization()(conv4)\n",
    "    x = layers.LeakyReLU(0.01)(conv4)\n",
    "    \n",
    "    conv5 = layers.Conv2D(64*8, 3, strides=2, padding='same')(x)\n",
    "    conv5 = layers.BatchNormalization()(conv5)\n",
    "    x = layers.LeakyReLU(0.01)(conv5)\n",
    "    \n",
    "    conv6 = layers.Conv2D(64*8, 3, strides=2, padding='same')(x)\n",
    "    conv6 = layers.BatchNormalization()(conv6)\n",
    "    x = layers.LeakyReLU(0.01)(conv6)\n",
    "    \n",
    "    conv7 = layers.Conv2D(64*8, 3, strides=2, padding='same')(x)\n",
    "    conv7 = layers.BatchNormalization()(conv7)\n",
    "    x = layers.LeakyReLU(0.01)(conv7)\n",
    "    \n",
    "    conv8 = layers.Conv2D(64*8, 3, strides=2, padding='same')(x)\n",
    "    conv8 = layers.BatchNormalization()(conv8)\n",
    "    x = layers.LeakyReLU(0.01)(conv8)\n",
    "    \n",
    "    conv9 = layers.Conv2D(64*8, 2, strides=1, padding='valid')(x)\n",
    "    conv9 = layers.BatchNormalization()(conv9)\n",
    "    x = layers.LeakyReLU(0.01)(conv9)\n",
    "    \n",
    "    deconv1 = layers.Conv2DTranspose(64*8, 2, strides=1)(x)\n",
    "    deconv1 = layers.BatchNormalization()(deconv1)\n",
    "    \n",
    "    x = layers.concatenate([deconv1, conv8])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv2 = layers.UpSampling2D(interpolation='bilinear')(x)\n",
    "    dconv2 = layers.Conv2D(64*8, 3, strides=1, padding='same')(dconv2)\n",
    "    dconv2 = layers.BatchNormalization()(dconv2)\n",
    "    \n",
    "    x = layers.concatenate([dconv2, conv7])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv3 = layers.UpSampling2D(interpolation='bilinear')(x)\n",
    "    dconv3 = layers.Conv2D(64*8, 3, strides=1, padding='same')(dconv3)\n",
    "    dconv3 = layers.BatchNormalization()(dconv3)\n",
    "\n",
    "    x = layers.concatenate([dconv3, conv6])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv4 = layers.UpSampling2D(interpolation='bilinear')(x)\n",
    "    dconv4 = layers.Conv2D(64*8, 3, strides=1, padding='same')(dconv4)\n",
    "    dconv4 = layers.BatchNormalization()(dconv4)\n",
    "\n",
    "    x = layers.concatenate([dconv4, conv5])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "\n",
    "    dconv5 = layers.UpSampling2D(interpolation='bilinear')(x)\n",
    "    dconv5 = layers.Conv2D(64*8, 3, strides=1, padding='same')(dconv5)\n",
    "    dconv5 = layers.BatchNormalization()(dconv5)\n",
    "\n",
    "    x = layers.concatenate([dconv5, conv4])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv6 = layers.UpSampling2D(interpolation='bilinear')(x)\n",
    "    dconv6 = layers.Conv2D(64*4, 3, strides=1, padding='same')(dconv6)\n",
    "    dconv6 = layers.BatchNormalization()(dconv6)\n",
    "\n",
    "    x = layers.concatenate([dconv6, conv3])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv7 = layers.UpSampling2D(interpolation='bilinear')(x)\n",
    "    dconv7 = layers.Conv2D(64*2, 3, strides=1, padding='same')(dconv7)\n",
    "    dconv7 = layers.BatchNormalization()(dconv7)\n",
    "\n",
    "    x = layers.concatenate([dconv7, conv2])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv8 = layers.UpSampling2D(interpolation='bilinear')(x)\n",
    "    dconv8 = layers.Conv2D(64, 3, strides=1, padding='same')(dconv8)\n",
    "    dconv8 = layers.BatchNormalization()(dconv8)\n",
    "\n",
    "    x = layers.concatenate([dconv8, conv1])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv9 = layers.Conv2DTranspose(3, 2, strides=2)(x)\n",
    "    last_layer = layers.Activation(activation='tanh')(dconv9)\n",
    "    \n",
    "    return tf.keras.Model(i, last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_p2p_generator_model_with_dropout():\n",
    "    i = layers.Input(shape=[512, 512, 1])\n",
    "    \n",
    "    conv1 = layers.Conv2D(64, 3, strides=2, padding='same')(i)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    x = layers.LeakyReLU(0.01)(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(64*2, 3, strides=2, padding='same')(x)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    x = layers.LeakyReLU(0.01)(conv2)\n",
    "    \n",
    "    conv3 = layers.Conv2D(64*4, 3, strides=2, padding='same')(x)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    x = layers.LeakyReLU(0.01)(conv3)\n",
    "    \n",
    "    conv4 = layers.Conv2D(64*8, 3, strides=2, padding='same')(x)\n",
    "    conv4 = layers.BatchNormalization()(conv4)\n",
    "    x = layers.LeakyReLU(0.01)(conv4)\n",
    "    \n",
    "    conv5 = layers.Conv2D(64*8, 3, strides=2, padding='same')(x)\n",
    "    conv5 = layers.BatchNormalization()(conv5)\n",
    "    x = layers.LeakyReLU(0.01)(conv5)\n",
    "    \n",
    "    conv6 = layers.Conv2D(64*8, 3, strides=2, padding='same')(x)\n",
    "    conv6 = layers.BatchNormalization()(conv6)\n",
    "    x = layers.LeakyReLU(0.01)(conv6)\n",
    "    \n",
    "    conv7 = layers.Conv2D(64*8, 3, strides=2, padding='same')(x)\n",
    "    conv7 = layers.BatchNormalization()(conv7)\n",
    "    x = layers.LeakyReLU(0.01)(conv7)\n",
    "    \n",
    "    conv8 = layers.Conv2D(64*8, 3, strides=2, padding='same')(x)\n",
    "    conv8 = layers.BatchNormalization()(conv8)\n",
    "    x = layers.LeakyReLU(0.01)(conv8)\n",
    "    \n",
    "    conv9 = layers.Conv2D(64*8, 2, strides=1, padding='valid')(x)\n",
    "    conv9 = layers.BatchNormalization()(conv9)\n",
    "    x = layers.LeakyReLU(0.01)(conv9)\n",
    "    \n",
    "    deconv1 = layers.Conv2DTranspose(64*8, 2, strides=1)(x)\n",
    "    deconv1 = layers.BatchNormalization()(deconv1)\n",
    "    deconv1 = layers.Dropout(0.5)(deconv1)\n",
    "    \n",
    "    x = layers.concatenate([deconv1, conv8])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv2 = layers.Conv2DTranspose(64*8, 2, strides=2)(x)\n",
    "    dconv2 = layers.BatchNormalization()(dconv2)\n",
    "    dconv2 = layers.Dropout(0.5)(dconv2)\n",
    "    \n",
    "    x = layers.concatenate([dconv2, conv7])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv3 = layers.Conv2DTranspose(64*8, 2, strides=2)(x)\n",
    "    dconv3 = layers.BatchNormalization()(dconv3)\n",
    "    dconv3 = layers.Dropout(0.5)(dconv3)\n",
    "\n",
    "    x = layers.concatenate([dconv3, conv6])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv4 = layers.Conv2DTranspose(64*8, 2, strides=2)(x)\n",
    "    dconv4 = layers.BatchNormalization()(dconv4)\n",
    "\n",
    "    x = layers.concatenate([dconv4, conv5])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "\n",
    "    dconv5 = layers.Conv2DTranspose(64*8, 2, strides=2)(x)\n",
    "    dconv5 = layers.BatchNormalization()(dconv5)\n",
    "\n",
    "    x = layers.concatenate([dconv5, conv4])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv6 = layers.Conv2DTranspose(64*4, 2, strides=2)(x)\n",
    "    dconv6 = layers.BatchNormalization()(dconv6)\n",
    "\n",
    "    x = layers.concatenate([dconv6, conv3])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv7 = layers.Conv2DTranspose(64*2, 2, strides=2)(x)\n",
    "    dconv7 = layers.BatchNormalization()(dconv7)\n",
    "\n",
    "    x = layers.concatenate([dconv7, conv2])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv8 = layers.Conv2DTranspose(64, 2, strides=2)(x)\n",
    "    dconv8 = layers.BatchNormalization()(dconv8)\n",
    "\n",
    "    x = layers.concatenate([dconv8, conv1])\n",
    "    x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    dconv9 = layers.Conv2DTranspose(3, 2, strides=2)(x)\n",
    "    last_layer = layers.Activation(activation='tanh')(dconv9)\n",
    "    \n",
    "    return tf.keras.Model(i, last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e09174",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_hm_generator_model()\n",
    "p2p_generator = make_p2p_generator_model_with_dropout()\n",
    "noise_image = tf.random.normal([1,1000,])\n",
    "generated_image = generator(noise_image, training=False)\n",
    "plt.imshow(generated_image[0]*255.0, cmap='gray')\n",
    "generator.summary()\n",
    "p2p_generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50939018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hm_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=[512, 512, 1]))\n",
    "    \n",
    "    div = [8,4,4,4,2,2,2]\n",
    "    div = [512/elem for elem in div]\n",
    "    \n",
    "    for n in div:\n",
    "        model.add(layers.Conv2D(n, 5, strides=1, padding='same'))\n",
    "        model.add(layers.LeakyReLU(0.2))\n",
    "        model.add(layers.MaxPool2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(1, 5, padding='same'))\n",
    "    \n",
    "    reduction_factor = 512 // (2**len(div))\n",
    "    model.add(layers.AveragePooling2D(pool_size=(reduction_factor, reduction_factor)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "def make_p2p_discriminator_model():  \n",
    "    input_a = layers.Input(shape=[512, 512, 1])\n",
    "    input_b = layers.Input(shape=[512, 512, 3])\n",
    "    \n",
    "    inputs = layers.concatenate([input_a, input_b])\n",
    "    x = inputs\n",
    "    \n",
    "    mul_factor = [1,2,4,8]\n",
    "    \n",
    "    for m in mul_factor:\n",
    "        x = layers.Conv2D(64*m, 3, strides=2, padding='same')(x)\n",
    "        x = layers.LeakyReLU(0.01)(x)\n",
    "    \n",
    "    out = layers.Conv2D(1, 3, strides=2, padding='same')(x)\n",
    "\n",
    "    return tf.keras.Model([input_a, input_b], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_hm_discriminator_model()\n",
    "discriminator.summary()\n",
    "p2p_discriminator = make_p2p_discriminator_model()\n",
    "p2p_discriminator.summary()\n",
    "print(discriminator(generated_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d732bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.MeanSquaredError()\n",
    "abs_loss = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = loss_obj(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = loss_obj(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return loss_obj(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def generator_p2p_loss(real_output, gen_output, fake_output):\n",
    "    x = loss_obj(tf.ones_like(fake_output), fake_output)\n",
    "    y = abs_loss(real_output, gen_output)\n",
    "    return x + 100*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5591243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = tf.keras.optimizers.RMSprop(1e-4)\n",
    "disc_optimizer = tf.keras.optimizers.RMSprop(1e-4)\n",
    "p2p_gen_optimizer = tf.keras.optimizers.RMSprop(1e-4)\n",
    "p2p_disc_optimizer = tf.keras.optimizers.RMSprop(1e-4)\n",
    "\n",
    "checkpoint_dir = 'gan_heightmaps'\n",
    "hm_checkpoint_prefix = os.path.join(checkpoint_dir, \"hm_ckpt\")\n",
    "hm_checkpoint = tf.train.Checkpoint(generator_optimizer=gen_optimizer,\n",
    "                                 discriminator_optimizer=disc_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "p2p_checkpoint_prefix = os.path.join(checkpoint_dir, \"p2p_ckpt\")\n",
    "p2p_checkpoint = tf.train.Checkpoint(generator_optimizer=p2p_gen_optimizer,\n",
    "                                 discriminator_optimizer=p2p_disc_optimizer,\n",
    "                                 generator=p2p_generator,\n",
    "                                 discriminator=p2p_discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc61500",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, 1000])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        \n",
    "    disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    \n",
    "    disc_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
    "    gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "@tf.function\n",
    "def p2p_train_step(real_heightmaps, real_textures):\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_textures = p2p_generator(real_heightmaps, training=True)\n",
    "        \n",
    "        real_output = p2p_discriminator([real_heightmaps, real_textures], training=True)\n",
    "        fake_output = p2p_discriminator([real_heightmaps, generated_textures], training=True)\n",
    "        \n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        gen_loss = generator_p2p_loss(real_textures, generated_textures, fake_output)\n",
    "        \n",
    "    disc_gradients = disc_tape.gradient(disc_loss, p2p_discriminator.trainable_variables)\n",
    "    gen_gradients = gen_tape.gradient(gen_loss, p2p_generator.trainable_variables)\n",
    "    \n",
    "    p2p_disc_optimizer.apply_gradients(zip(disc_gradients, p2p_discriminator.trainable_variables))\n",
    "    p2p_gen_optimizer.apply_gradients(zip(gen_gradients, p2p_generator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_and_generate_images(model, p2p_model, epoch, test_output):\n",
    "    predictions = model(test_output, training=False)\n",
    "    p2p_predictions = p2p_model(predictions, training=False)  \n",
    "        \n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(len(test_output)):\n",
    "        plt.subplot(4,4,i*2+1)\n",
    "        plt.imshow(predictions[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(4,4,i*2+2)\n",
    "        plt.imshow((p2p_predictions[i]*127.5+127.5)/255.0)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.savefig('gan_heightmaps_hm_image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    _=plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    print('Beginning to train...')\n",
    "    \n",
    "    history = pd.DataFrame(['gen_loss', 'disc_loss', 'p2p_gen_loss', 'p2p_disc_loss'])\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        epoch_gen_loss = tf.keras.metrics.Mean()\n",
    "        epoch_disc_loss = tf.keras.metrics.Mean()\n",
    "        epoch_p2p_gen_loss = tf.keras.metrics.Mean()\n",
    "        epoch_p2p_disc_loss = tf.keras.metrics.Mean()\n",
    "        for i in range(len(f['xt']) // BATCH_SIZE):\n",
    "            images = dataset.next()\n",
    "            real_heightmaps = images[:,:,:,3]\n",
    "            real_textures = images[:,:,:,0:3]\n",
    "            \n",
    "            gen_loss, disc_loss = train_step(real_heightmaps)\n",
    "            p2p_gen_loss, p2p_disc_lodd = p2p_train_step(real_heightmaps, real_textures)\n",
    "            epoch_gen_loss.update_state(gen_loss)\n",
    "            epoch_disc_loss.update_state(disc_loss)\n",
    "            epoch_p2p_gen_loss.update_state(p2p_gen_loss)\n",
    "            epoch_p2p_disc_loss.update_state(p2p_disc_lodd)\n",
    "\n",
    "        show_and_generate_images(generator, p2p_generator, epoch + 1, seed)\n",
    "        stats = 'Epoch {0} took {1} seconds. Gen_loss: {2:0.3f}, Disc_loss: {3:0.3f}, p2p_gen_loss: {4:0.3f}, p2p_disc_loss: {5:0.3f}'\n",
    "        print(stats.format(epoch + 1, int(time.time() - start), \n",
    "                           epoch_gen_loss.result().numpy(), \n",
    "                           epoch_disc_loss.result().numpy(),\n",
    "                           epoch_p2p_gen_loss.result().numpy(),\n",
    "                           epoch_p2p_disc_loss.result().numpy()))\n",
    "        history = history.append({'gen_loss': epoch_gen_loss.result().numpy(), \n",
    "                                  'disc_loss': epoch_disc_loss.result().numpy(),\n",
    "                                  'p2p_gen_loss': epoch_p2p_gen_loss.result().numpy(),\n",
    "                                  'p2p_disc_loss': epoch_p2p_disc_loss.result().numpy()}, \n",
    "                                  ignore_index=True)\n",
    "        if (epoch+1) % 50 == 0:\n",
    "            hm_checkpoint.save(file_prefix = hm_checkpoint_prefix)\n",
    "            p2p_checkpoint.save(file_prefix = p2p_checkpoint_prefix)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc025c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "seed = tf.random.normal([8, 1000])\n",
    "history = train(img_it, EPOCHS)\n",
    "history.index = history.index + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
